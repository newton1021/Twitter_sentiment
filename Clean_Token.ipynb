{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import re \n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/theDoctor/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(filepath):\n",
    "    df = pd.read_csv(filepath, encoding='latin-1')\n",
    "    df.columns = [\"text\",\"sentiment\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "def load_text_data(filename):\n",
    "    textfile = open(filename, \"r\")\n",
    "    for tweet in textfile:\n",
    "        print(tweet)\n",
    "        parts = tweet.split(',')\n",
    "        if len(parts) > 2:\n",
    "            newTweet = [parts[0],parts[1], 0, \"\".join(parts[3:])]\n",
    "            data.append(newTweet)\n",
    "    textfile.close()\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = [\"User\", \"Date\", \"Retweet\", \"text\"]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def delete_redundant_cols(df, cols):\n",
    "    for col in cols:\n",
    "        del df[col]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi prepar exam'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_tweet_text(tweet):\n",
    "\n",
    "    tweet = tweet.lower()\n",
    "\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\",\"\",tweet, flags=re.MULTILINE)   \n",
    "\n",
    "    tweet = tweet.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "\n",
    "    tweet = re.sub(r'\\@\\w+|\\#',\"\",tweet)\n",
    "\n",
    "    tweet_tokens = word_tokenize(tweet)\n",
    "    filtered_words = [word for word in tweet_tokens if word not in stop_words]\n",
    "\n",
    "    ps = PorterStemmer()\n",
    "    stemmed_words = [ps.stem(w) for w in filtered_words]\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemma_words = [lemmatizer.lemmatize(w, pos='a') for w in stemmed_words]\n",
    "\n",
    "    return \" \".join(lemma_words)\n",
    "preprocess_tweet_text(\"Hi there, how are you preparing for your exams?\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector(train_fit):\n",
    "    vector = TfidfVectorizer(sublinear_tf=True)\n",
    "    vector.fit(train_fit)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_string(sentiment):\n",
    "    if sentiment < -0.1:\n",
    "        return \"Negative\"\n",
    "    elif sentiment < 0.1:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 676 entries, 0 to 675\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   User       676 non-null    object \n",
      " 1   Date       676 non-null    object \n",
      " 2   Retweet    676 non-null    int64  \n",
      " 3   text       676 non-null    object \n",
      " 4   cleanText  676 non-null    object \n",
      " 5   sentiment  676 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 31.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HarunaMakoleA, Sat Sep 04 15:22:51 +0000 2021, False, @NomthandazoPe11 #happy Sunday too beautiful ğŸ–ğŸ–\n",
      "\n",
      "beyondsummitllc, Sat Sep 04 15:21:57 +0000 2021, False, Save moreâ€¦ play more!  Our entire store is discounted until 9/6/21.  #love #instagood #photooftheday #beautifulâ€¦ https://t.co/mm7Z4hM55s\n",
      "\n",
      "Rohitwavhal1, Sat Sep 04 15:21:40 +0000 2021, False, @AnviFightsSMA @Vikramtek @aajtak Please help us to save Anvi ğŸ™ğŸ»\n",
      "\n",
      "\n",
      "\n",
      "#anvifightssma #wesupportanvi #anviwavhalâ€¦ https://t.co/WZFP2vlV4R\n",
      "\n",
      "PeterLamya, Sat Sep 04 15:21:20 +0000 2021, False, We could never have loved the earth so well if we had had no sisterhood in it.\n",
      "\n",
      "#PeterLamyaPhotographyâ€¦ https://t.co/0BSHWQmrqA\n",
      "\n",
      "jusdax, Sat Sep 04 15:21:02 +0000 2021, False, if you have the ability to love . Love yourself first.\n",
      "\n",
      "#adityabruh #adityaforever #jusdaxbruh #cheekfiller #fillersâ€¦ https://t.co/c4zY0ByqFf\n",
      "\n",
      "pawzpace, Sat Sep 04 15:16:36 +0000 2021, False, Experience the heist on @pawzpace .... Get up to 60% off on all the grooming services.\n",
      "\n",
      "\n",
      "\n",
      "For more updates, follow usâ€¦ https://t.co/5Jq6OAvHLB\n",
      "\n",
      "jayjonny01, Sat Sep 04 15:11:25 +0000 2021, False, Thanks to fantastic work by James @DJFpainting we now have a fabulous lounge, weâ€™ve gone from cream to soft blue ~â€¦ https://t.co/izD268Jfm7\n",
      "\n",
      "Tanya_R_Steele, Sat Sep 04 15:10:41 +0000 2021, False, ~Wishing @Beyonce Knowles-Carter an amazing 40th! And a Big #Happy #Happy to both she and Ms. @Oprah !!! â¤ï¸ğŸ‘ğŸ‘ğŸ‘ https://t.co/YSdx3H9t6a\n",
      "\n",
      "StayHealthy07, Sat Sep 04 15:08:34 +0000 2021, False, What Makes Urine Smell Strong or Foul?\n",
      "\n",
      "https://t.co/8MjtzutkXA\n",
      "\n",
      "#tagfire #lifestyle #health #life #LOL #Yoga #foodâ€¦ https://t.co/25vmMNPztK\n",
      "\n",
      "aziz_basha01, Sat Sep 04 15:07:59 +0000 2021, False, The Opening of the Spiritual Heart.\n",
      "\n",
      "#instagood #love #instagram #like #photooftheday #follow #photographyâ€¦ https://t.co/lmAr28ZYoK\n",
      "\n",
      "dtpjr64, Sat Sep 04 15:07:56 +0000 2021, False, ğŸ“· Ack to my #happyplace this morning! #happy #ocean #gardencity #myrtlebeach #myrtlebeachsc #southcarolina #cigarâ€¦ https://t.co/LAa5ArKG5a\n",
      "\n",
      "dtpjr64, Sat Sep 04 15:07:54 +0000 2021, False, Ack to my #happyplace  this morning!  \n",
      "\n",
      "#happy #ocean #gardencity #myrtlebeach #myrtlebeachsc #southcarolina #cigarâ€¦ https://t.co/FRgbga4fdw\n",
      "\n",
      "runawaygirl248, Sat Sep 04 15:07:44 +0000 2021, False, Happiness is...swimming and brings back sticks ğŸ¾ğŸ¾ğŸ˜ğŸ˜˜\n",
      "\n",
      "#cavpack #cavaliers #cavaliersarespecial #happy #dogsoftwitter https://t.co/ahxn6BoAxM\n",
      "\n",
      "AbodeTelugu, Sat Sep 04 15:07:29 +0000 2021, False, The Opening of the Spiritual Heart.\n",
      "\n",
      "#instagood #love #instagram #like #photooftheday #follow #photographyâ€¦ https://t.co/qpIkjFH3m1\n",
      "\n",
      "ChanJule, Sat Sep 04 15:05:18 +0000 2021, False, Dressing up with @roseofsharon.singapore #singapore #fyp #dress #happy #rosambassador #myjoyfulmomentsâ€¦ https://t.co/gWvDIzqW5L\n",
      "\n",
      "ktlh2, Sat Sep 04 15:04:06 +0000 2021, False, @GovAbbott will no longer be #Governor nor #President and that makes me #Happy ! https://t.co/SyiZ5gheDQ\n",
      "\n",
      "iori_sns, Sat Sep 04 15:03:41 +0000 2021, False, I found a girl with a very #cute voice.\n",
      "\n",
      "The PV is also very #funny , \n",
      "\n",
      "so it makes me #happy .\n",
      "\n",
      "\n",
      "\n",
      "Thatâ€™s â€œDANCE MONKEYâ€¦ https://t.co/L5s5Un8Ld0\n",
      "\n",
      "Badal28289982, Sat Sep 04 15:02:48 +0000 2021, False, #Happy #Teachers'#Day in advance! Let's pledge to propagate the philosophy of #Radhakrishnan !\n",
      "\n",
      "JackieYunTweets, Sat Sep 04 15:02:34 +0000 2021, False, â€œAt your next #networking opportunity youâ€™re going to smile. Youâ€™re going to #smile at your friends, the other guesâ€¦ https://t.co/DiIeymc37d\n",
      "\n",
      "bmp_network, Sat Sep 04 15:01:06 +0000 2021, False, Daily Affirmation\n",
      "\n",
      "\n",
      "\n",
      "Be motivated!\n",
      "\n",
      "Visit https://t.co/bmlHlMQlbo\n",
      "\n",
      "\n",
      "\n",
      "#ThoughtOfTheDay #motivation #inspirationâ€¦ https://t.co/dOBojFiRof\n",
      "\n",
      "BetterknowYou, Sat Sep 04 15:00:34 +0000 2021, False, Check out this product ğŸ˜€SF_F1 Shoe Drawstring BagsğŸ˜€\n",
      "\n",
      "by PULL UP AND SHOP starting at $12.99.\n",
      "\n",
      "Order now:â€¦ https://t.co/Uln11fBhpH\n",
      "\n",
      "BeautySkinYourN, Sat Sep 04 15:00:00 +0000 2021, False, 10 WAYS TO PROTECT YOUR KIDS FROM PREDATORS\n",
      "\n",
      "\n",
      "\n",
      "https://t.co/FtXS29EeuO\n",
      "\n",
      "\n",
      "\n",
      "#parenting #children #momlife #leadershipâ€¦ https://t.co/feuczikQZJ\n",
      "\n",
      "AZSoldiersBF, Sat Sep 04 15:00:00 +0000 2021, False, The long weekend is here!  What are your plans?\n",
      "\n",
      "\n",
      "\n",
      "#laborday #labordayweekend #happylaborday #monday #labor #workâ€¦ https://t.co/MGDPy8pfcN\n",
      "\n",
      "happytoddlernow, Sat Sep 04 14:59:48 +0000 2021, False, #happy Hopscotch Chalk https://t.co/blCzDG2dUT https://t.co/d6T8ECzBMR\n",
      "\n",
      "redbone_esha2x, Sat Sep 04 14:59:20 +0000 2021, False, The chi now on BET #happy\n",
      "\n",
      "BrielleMade, Sat Sep 04 14:57:37 +0000 2021, False, ğŸ’¬Discover a wonderful #Travel \n",
      "\n",
      "\n",
      "\n",
      "#happy ğŸ˜  \n",
      "\n",
      "ğŸ¾#traveler\n",
      "\n",
      "ğŸ“š#photobook\n",
      "\n",
      "â¤ï¸ #memories \n",
      "\n",
      " ğŸ‰#makingmagic  \n",
      "\n",
      "ğŸ¥¾#travelbook   \n",
      "\n",
      "ğŸŒ¿â€¦ https://t.co/06X4thrXLG\n",
      "\n",
      "FlightPalatine, Sat Sep 04 14:57:33 +0000 2021, False, ğŸ“· #Strong, #happy #poledancers Itâ€™s #graduation! Which meansâ€¦ NEW 8-Week Series in both #Pole and #Aerial begins thâ€¦ https://t.co/58tas2XPbn\n",
      "\n",
      "BrielleMade, Sat Sep 04 14:57:16 +0000 2021, False, ğŸ’¬Discover a wonderful #Travel \n",
      "\n",
      "\n",
      "\n",
      "#happy ğŸ˜  \n",
      "\n",
      "ğŸ¾#traveler\n",
      "\n",
      "ğŸ“š#photobook\n",
      "\n",
      "â¤ï¸ #memories \n",
      "\n",
      " ğŸ‰#makingmagic  \n",
      "\n",
      "ğŸ¥¾#travelbook   \n",
      "\n",
      "ğŸŒ¿â€¦ https://t.co/nPWR2GacUA\n",
      "\n",
      "wife_ackee0774, Sat Sep 04 14:57:00 +0000 2021, False, I have a spectacular view in front of me.\n",
      "\n",
      "#love #instagood #happy #buttocks #life #beautifulwife #japan #wifeâ€¦ https://t.co/f5QRngIxNA\n",
      "\n",
      "drsilkymd, Sat Sep 04 14:55:01 +0000 2021, False, Don't miss my live this Tuesday at 3:00 PM ET! I'm going to continue my hunger series and this week we're talking aâ€¦ https://t.co/6tOO8SIqnj\n",
      "\n",
      "BennettDebi, Sat Sep 04 14:54:26 +0000 2021, False, This weekâ€™s online classesğŸ¤©\n",
      "\n",
      "\n",
      "\n",
      "Please check my website \n",
      "\n",
      "https://t.co/RfB9AF7flz for more info about me &amp; my classes ğŸ¤©â€¦ https://t.co/9dgGkVmJG1\n",
      "\n",
      "Jeremy95182671, Sat Sep 04 14:53:38 +0000 2021, False, Well well well every #doge has his day! #ToTheMoon #DogecoinToTheMoon #DogecoinRise #happy anniversary to my wifeâ€¦ https://t.co/Vqfoan2LIx\n",
      "\n",
      "zeo55403890, Sat Sep 04 14:53:37 +0000 2021, False, #Happy Vmin day\n",
      "\n",
      "pieterstaaks, Sat Sep 04 14:52:10 +0000 2021, False, little happy friend, he only likes me because i'll throw his skippyball. ğŸ•\n",
      "\n",
      "\n",
      "\n",
      "#dogsofinstagram #dog #dogslifeâ€¦ https://t.co/UUVYRAFzJB\n",
      "\n",
      "djpilates1, Sat Sep 04 14:51:03 +0000 2021, False, This weekâ€™s online classesğŸ¤©\n",
      "\n",
      "\n",
      "\n",
      "Please check my website \n",
      "\n",
      "https://t.co/quH7LhSv2y for more info about me &amp; my classes ğŸ¤©â€¦ https://t.co/Lxy09RuEcU\n",
      "\n",
      "AskDrCovington, Sat Sep 04 14:50:03 +0000 2021, False, For the #love of #OccupationalTherapy - #OT365 #FrederickCovington #TheTherapyInstitute #TheOTGeniusBox #instagoodâ€¦ https://t.co/p4IGiq70Ey\n",
      "\n",
      "tigerfunk69, Sat Sep 04 14:48:30 +0000 2021, False, guess what guysâ€¦i think itâ€™s working #soak #happy #rejuvenated https://t.co/DDjCyBsp3R\n",
      "\n",
      "Caremark_HBB, Sat Sep 04 14:47:32 +0000 2021, False, Good friends and family are the biggest blessings by the god.ğŸ’¯\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      "ğŸ“: 0116 429 1100\n",
      "\n",
      "ğŸ“©: blaby@caremark.co.ukâ€¦ https://t.co/t5LyGTUilL\n",
      "\n",
      "Pahadi__Queen, Sat Sep 04 14:47:13 +0000 2021, False, ğ—œ ğ—®ğ—º ğ˜ğ—¿ğ˜†ğ—¶ğ—»ğ—´ ğ˜ğ—¼ ğ—¯ğ—² #ğ—µğ—®ğ—½ğ—½ğ˜†â˜ºï¸\n",
      "\n",
      "\n",
      "\n",
      "#ğ—¯ğ˜‚ğ˜ ğ—œ ğ—°ğ—®ğ—»'ğ˜ğŸ¥ºğŸ¥€\n",
      "\n",
      "billiefmradio, Sat Sep 04 14:46:59 +0000 2021, False, BeyoncÃ© 40TH.. #Beyonce #Happy 40th #HappyBirthdayBeyonce #Queen B https://t.co/A1NHnnbYGH\n",
      "\n",
      "knobutter, Sat Sep 04 14:45:48 +0000 2021, False, She got them ğŸ€Winter ReadyğŸ€ feet ğŸŒ¬ğŸ»ğŸ’—âœ¨ #happy #feet #fluffy #treat https://t.co/oKbcjdZgIw https://t.co/joMg1PBPeE\n",
      "\n",
      "HanByeol_91, Sat Sep 04 14:43:29 +0000 2021, False, If at least youâ€™re happy,\n",
      "\n",
      "itâ€™s a happy ending\n",
      "\n",
      "Iâ€™m not being sarcastic,\n",
      "\n",
      "I hope you know I mean it\n",
      "\n",
      "#HAPPY\n",
      "\n",
      "MackFirby, Sat Sep 04 14:43:18 +0000 2021, False, ğŸ’¥ 13!! Happy Birthday to our teenager @aidenkilshaw ğŸ‚ ğŸ ğŸ‰ \n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      "#teenager #13birthday #instagoodâ€¦ https://t.co/Zh2P7dYnX5\n",
      "\n",
      "Flowerdoo1, Sat Sep 04 14:42:33 +0000 2021, False, #Happy #Labor #Day\n",
      "\n",
      "Get a free 25W USB-C PD Wall #Charger\n",
      "\n",
      "with purchase of $80 or more.\n",
      "\n",
      "SHOP NOWâ€¦ https://t.co/py1fuANA0M\n",
      "\n",
      "beardedbiggs, Sat Sep 04 14:40:45 +0000 2021, False, Big 30 miles around Kettering this morning. Not good cramping up at 25 miles!\n",
      "\n",
      "#mtb #mountainbiking #mountainbikeâ€¦ https://t.co/LC2PKmmCBx\n",
      "\n",
      "yelliabella, Sat Sep 04 14:40:35 +0000 2021, False, I sit pretty n the house #happy\n",
      "\n",
      "HealthyandFitn8, Sat Sep 04 14:40:02 +0000 2021, False, 8 Health Risks Of Long Commute To Work https://t.co/98tBWOcpPW\n",
      "\n",
      "#tagfire #lifestyle #health #life #LOL #Yoga #foodâ€¦ https://t.co/kRy3vKxvCx\n",
      "\n",
      "Vindorephotos, Sat Sep 04 14:39:25 +0000 2021, False, FAITH tells me that no matter whatâ€™s ahead of me, the Most High God YAH is already there. Donâ€™t worry! #Faith #Sabbath #Happy #Rest #Bible\n",
      "\n",
      "LatinoLdnOnt, Sat Sep 04 14:39:22 +0000 2021, False, â€œLife shrinks or expands in proportion to oneâ€™s courage.â€ â€“ Anais Nin #life #strings #expands #one #courageâ€¦ https://t.co/BHSQea5H54\n",
      "\n",
      "kurtwvoigt, Sat Sep 04 14:37:00 +0000 2021, False, Day 939\n",
      "\n",
      "\n",
      "\n",
      "One moment can define the love of a lifetime. \n",
      "\n",
      "__\n",
      "\n",
      "\n",
      "\n",
      "#life #live #love #loveyourself #iloveyou #lovepoemâ€¦ https://t.co/nbHQFF8lM4\n",
      "\n",
      "wellerpharmacy, Sat Sep 04 14:36:22 +0000 2021, False, We are #OPEN #Saturday and #Sunday September 4 &amp; 5 \n",
      "\n",
      "10 am to 3 pm and WE ARE OPEN #MONDAY #September 6 from 9 am toâ€¦ https://t.co/OwtfzINeut\n",
      "\n",
      "StayHealthy07, Sat Sep 04 14:34:21 +0000 2021, False, 26 Tips To Lose Weight In A Healthy Way\n",
      "\n",
      "https://t.co/I0hbPJSt06\n",
      "\n",
      "#tagfire #lifestyle #health #life #LOL #Yoga #foodâ€¦ https://t.co/lGZXyAxUpU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_text_data(\"datasets/dataset 2021090410_24_02.txt\")\n",
    "# Remove unwanted columns from dataset\n",
    "# n_dataset = remove_unwanted_cols(dataset, ['t_id', 'created_at', 'query', 'user'])\n",
    "#Preprocess data\n",
    "dataset[\"cleanText\"] = dataset['text'].apply(preprocess_tweet_text)\n",
    "\n",
    "sent = []\n",
    "\n",
    "for x in dataset['cleanText']:\n",
    "    s = TextBlob(x).sentiment.polarity\n",
    "    if s < -0.1:\n",
    "        r = -1\n",
    "    elif s > 0.1:\n",
    "        r = 1\n",
    "    else:\n",
    "        r = 0\n",
    "    sent.append(r) \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "dataset[\"sentiment\"] = sent\n",
    "\n",
    "\n",
    "\n",
    "# Split dataset into Train, Test\n",
    "\n",
    "# Same tf vector will be used for Testing sentiments on unseen trending data\n",
    "tf_vector = get_feature_vector(np.array(dataset['cleanText']).ravel())\n",
    "X = tf_vector.transform(np.array(dataset['cleanText']).ravel())\n",
    "y = np.array(dataset['sentiment']).ravel()\n",
    "# y = y.astype('float')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)\n",
    "\n",
    "# Training Naive Bayes model\n",
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train, y_train)\n",
    "y_predict_nb = NB_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_predict_nb))\n",
    "\n",
    "# Training Logistics Regression model\n",
    "LR_model = LogisticRegression(solver='lbfgs')\n",
    "LR_model.fit(X_train, y_train)\n",
    "y_predict_lr = LR_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_predict_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Date</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>text</th>\n",
       "      <th>cleanText</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PeterLamya</td>\n",
       "      <td>Sat Sep 04 15:21:20 +0000 2021</td>\n",
       "      <td>0</td>\n",
       "      <td>We could never have loved the earth so well i...</td>\n",
       "      <td>could never love earth well sisterhood</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>pieterstaaks</td>\n",
       "      <td>Sat Sep 04 14:52:10 +0000 2021</td>\n",
       "      <td>0</td>\n",
       "      <td>little happy friend he only likes me because ...</td>\n",
       "      <td>littl happi friend like ill throw skippybal ğŸ•</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>HanByeol_91</td>\n",
       "      <td>Sat Sep 04 14:43:29 +0000 2021</td>\n",
       "      <td>0</td>\n",
       "      <td>If at least youâ€™re happy\\n</td>\n",
       "      <td>least â€™ happi</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>PeterLamya</td>\n",
       "      <td>Sat Sep 04 15:21:20 +0000 2021</td>\n",
       "      <td>0</td>\n",
       "      <td>We could never have loved the earth so well i...</td>\n",
       "      <td>could never love earth well sisterhood</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>pieterstaaks</td>\n",
       "      <td>Sat Sep 04 14:52:10 +0000 2021</td>\n",
       "      <td>0</td>\n",
       "      <td>little happy friend he only likes me because ...</td>\n",
       "      <td>littl happi friend like ill throw skippybal ğŸ•</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>pieterstaaks</td>\n",
       "      <td>Sat Sep 04 14:52:10 +0000 2021</td>\n",
       "      <td>0</td>\n",
       "      <td>little happy friend he only likes me because ...</td>\n",
       "      <td>littl happi friend like ill throw skippybal ğŸ•</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>HanByeol_91</td>\n",
       "      <td>Sat Sep 04 14:43:29 +0000 2021</td>\n",
       "      <td>0</td>\n",
       "      <td>If at least youâ€™re happy\\n</td>\n",
       "      <td>least â€™ happi</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>PeterLamya</td>\n",
       "      <td>Sat Sep 04 15:21:20 +0000 2021</td>\n",
       "      <td>0</td>\n",
       "      <td>We could never have loved the earth so well i...</td>\n",
       "      <td>could never love earth well sisterhood</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>pieterstaaks</td>\n",
       "      <td>Sat Sep 04 14:52:10 +0000 2021</td>\n",
       "      <td>0</td>\n",
       "      <td>little happy friend he only likes me because ...</td>\n",
       "      <td>littl happi friend like ill throw skippybal ğŸ•</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>HanByeol_91</td>\n",
       "      <td>Sat Sep 04 14:43:29 +0000 2021</td>\n",
       "      <td>0</td>\n",
       "      <td>If at least youâ€™re happy\\n</td>\n",
       "      <td>least â€™ happi</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              User                             Date  Retweet  \\\n",
       "3       PeterLamya   Sat Sep 04 15:21:20 +0000 2021        0   \n",
       "33    pieterstaaks   Sat Sep 04 14:52:10 +0000 2021        0   \n",
       "41     HanByeol_91   Sat Sep 04 14:43:29 +0000 2021        0   \n",
       "55      PeterLamya   Sat Sep 04 15:21:20 +0000 2021        0   \n",
       "85    pieterstaaks   Sat Sep 04 14:52:10 +0000 2021        0   \n",
       "...            ...                              ...      ...   \n",
       "1073  pieterstaaks   Sat Sep 04 14:52:10 +0000 2021        0   \n",
       "1081   HanByeol_91   Sat Sep 04 14:43:29 +0000 2021        0   \n",
       "1095    PeterLamya   Sat Sep 04 15:21:20 +0000 2021        0   \n",
       "1125  pieterstaaks   Sat Sep 04 14:52:10 +0000 2021        0   \n",
       "1133   HanByeol_91   Sat Sep 04 14:43:29 +0000 2021        0   \n",
       "\n",
       "                                                   text  \\\n",
       "3      We could never have loved the earth so well i...   \n",
       "33     little happy friend he only likes me because ...   \n",
       "41                           If at least youâ€™re happy\\n   \n",
       "55     We could never have loved the earth so well i...   \n",
       "85     little happy friend he only likes me because ...   \n",
       "...                                                 ...   \n",
       "1073   little happy friend he only likes me because ...   \n",
       "1081                         If at least youâ€™re happy\\n   \n",
       "1095   We could never have loved the earth so well i...   \n",
       "1125   little happy friend he only likes me because ...   \n",
       "1133                         If at least youâ€™re happy\\n   \n",
       "\n",
       "                                          cleanText  sentiment  \n",
       "3            could never love earth well sisterhood         -1  \n",
       "33    littl happi friend like ill throw skippybal ğŸ•         -1  \n",
       "41                                    least â€™ happi         -1  \n",
       "55           could never love earth well sisterhood         -1  \n",
       "85    littl happi friend like ill throw skippybal ğŸ•         -1  \n",
       "...                                             ...        ...  \n",
       "1073  littl happi friend like ill throw skippybal ğŸ•         -1  \n",
       "1081                                  least â€™ happi         -1  \n",
       "1095         could never love earth well sisterhood         -1  \n",
       "1125  littl happi friend like ill throw skippybal ğŸ•         -1  \n",
       "1133                                  least â€™ happi         -1  \n",
       "\n",
       "[66 rows x 6 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset['sentiment'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_file_name = \"trending_tweets/08-04-2020-1586291553-tweets.csv\"\n",
    "# test_ds = load_dataset(test_file_name, [\"t_id\", \"hashtag\", \"created_at\", \"user\", \"text\"])\n",
    "# test_ds = remove_unwanted_cols(test_ds, [\"t_id\", \"created_at\", \"user\"])\n",
    "\n",
    "# # Creating text feature\n",
    "# test_ds.text = test_ds[\"text\"].apply(preprocess_tweet_text)\n",
    "# test_feature = tf_vector.transform(np.array(test_ds.iloc[:, 1]).ravel())\n",
    "\n",
    "# # Using Logistic Regression model for prediction\n",
    "# test_prediction_lr = LR_model.predict(test_feature)\n",
    "\n",
    "# # Averaging out the hashtags result\n",
    "# test_result_ds = pd.DataFrame({'hashtag': test_ds.hashtag, 'prediction':test_prediction_lr})\n",
    "# test_result = test_result_ds.groupby(['hashtag']).max().reset_index()\n",
    "# test_result.columns = ['heashtag', 'predictions']\n",
    "# test_result.predictions = test_result['predictions'].apply(int_to_string)\n",
    "\n",
    "# print(test_result)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "c1e83760cadaf87b0a0f9ca95f844ef4947bb6840a3db1438c78c07aa1fb0afe"
  },
  "kernelspec": {
   "display_name": "Python Data",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
